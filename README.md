#System Requirements

The clustering analysis has been verified to work with python 2.7.15. And starcode was compiled with gcc version 4.8.5. To perform analysis in a timely fashion, we use a high performance computing service at NC State Univeristy interfaced with using the IBM LSF platform. Thus, this code should be capable of running on any parallel processing environment that supports LSF job management. 

#Nat Com Submission Overview

This repository contains all tools and code used to cluster strands obtained from preview experiments. At the top level of this repository there are 6 directories of raw fastq data that is the inputs to clustering to generate figures in the paper. The directory preview_11_23_2020 is used to generate Figure 3c, and the directories preview_12_16_2020_access_sets_n organize fastq data for different file accesses and are used to generate suppplemental data related to Figures 3e-h and supplemental Figures 3b-c and 4b. The directory file-sequencer-analysis contains the tools and scripts used to launch parallelized jobs to perform clustering. For each of the aforementioned fastq directories, there are identically named directories appended with "Stripped". These directories contain the raw fastq data, but just strands with other information removed. These stripped files are ultimiately used for clustering, and can be generated by following the instructions bellow.

With the stripped raw fastq data, clustering is done by pairing each raw data with a bias configuration file and a bias directory under the file-sequencer-analysis/bias_lib directory. Under the file-sequencer-analysis/bias_lib directory there are 3 sub-directory options. 1) base_preview_lib - original encodings of each preview file, no modifications, these are the strands stored before acces 2) preview_0HD - This directory has a file for every encoded file, but only the inner-amplified region of each strand is stored, and all inner primers used for approximate hamming distance access are converted to the amplifying 0 hamming distance primer. These strands represent what we expect after accessing a set of primers that are some distance (0,2,4) from an accessing primer. There are also 2 other files in this directory that represent background strands used for high background accesses ( 3) preview_error_primer - only has 1 file of strands related to file 2 (wright glider), and this file is generated to include strands that may arise from off-target amplification within the payload of a strand. These bias strands are used to generate the results shown in Figure 3c. This "error" file is generated by the tool at the path file-sequencer-analysis/misc/preview_strip.py. You can perform the command `python preview_strip.py -h` to see help options for this script.

A configuration file for clustering is chosen from the file-sequencer-analsyis/config_lib/config_preview_2020 directory, with the file haveing the form bias_*.json and the wildcard * portion matching the name of a given set of fastq data. To generate the raw data for the number of reads of each strand, follow the directions below after `make align`, and use the configuration files that having matching names to each set of data referenced earlier. 


# Clustering Analysis Overview

This repository can be used as a tool to aid in the analysis of sequencing data, specifically sequencing data that represents DNA strands that encode data for an actual file. The main mechanism for the analysis is based on the starcode clustering algorithm (https://github.com/gui11aume/starcode). At a high level the clustering algorithm groups together strands that are within some small edit distance of each other. This is based on the idea that each file's encoded logical strands will have many copies, but the copies may be slightly corrupted due to insertions, deletions, and substitutions. However,it is assumed that the non-corrupted strands will be sequenced at a much higher rate than those that have errors, and the clustering finds centroids that have high amounts of reads compared to strands that have a close edit distance match to it. The close edit distance mathces are then included in the cluster around that centroid. The analysis in this repository leverages the clustering mechanism by seeding the clustering pass with strands we expect to see. For example, with an encoded file, we take the encoded strands without error, replicate them several times, and then include the replicated encoded strands with the fastq sequencing file. This establishes centroids automatically at the strands that we are interested in, and the clustering algorithm will group the sequencing reads to the centroids with the closest edit distance. After placing each sequencing strand in a cluster, a mapping file is created to store which file strand a sequencing strand belongs to. This mapping information can then be used for analysis in a subsequent script to develop read distributions, error rates, etc.

# Clustering Analysis Set up and Tools

To set up the analysis, first starcode needs to be downloaded and compiled. This can be done with the following command after cloning this directory:

`make init`

After compiling this, the files that indicate the canonical strands that should form the centroids need to be set up, and configuration files need to be created. There are examples of configuration files and canonical strand files found in the directories config\_lib and bias\_lib, respectively. Canonical strand files should just be those files that represent the encoded strands for the library, and the configuration files are used to indicate to the clustering analysis which files from the library will be used to set up the centroids, e.g. you can chose a configuration that creates centroids only using strands from 1 file in the library. There are two specific configuration files that need to be created. One is an alignment configuration that is used to pair a *sequencing index DNA sequence* with each *experiment* in your data set. Whether this actually gets used on not depends on how the sequencing machine/service prepares the data. If it *does* remove the *sequencing index*, this configuration file is ignored and the scripts/alignment.sh script needs to be configured to reflect that. If the index does not get removed the alignment scripts will pick out the best matching parts of each sequencing strand that match to the index, and the remaining bases between the index regions are taken and output to a stripped fastq directory. Once an alignment configuration script is made that reflects the experiments being stripped, the following steps need to be done to modify the scripts/alignment.sh shell script.

1. open scripts/alignment.sh
1. modify the `fastQDir` variable to point to the path of the fastq files you want to operate on
1. (optional) modify `outputDir` to be the path where stripped fastq files are to be dumped
1. modify `alignmentFile` to be the path of the alignment configuration file for the fastq files being stripped
1. modify the python command portion of the `bsub` command with the `--skip_alignment` if no alignment is needed, otherwise remove it or do not add the flag

After following the previous steps run the following command from the top directory for the repo:

`make align`

There should now be a directory populated with stripped fastq files. The next step is to run the clustering process to get a mapping of the sequencing strands. This is where the second config file (known as biasing files) is needed, which indicates which file should be used for seeding. The following steps need to be taken after creating the biasing file:

1. open scripts/cluster.sh
1. modify the `strippedFastQDir` variable  to point to the path with stripped fastq files (files obtained after the previous set of steps)
1. modify the `outputDir` variable to point to the path to place mapping results after clustering
1. modify the `biasDir` variable to point to path of the directory of expected strands that clustering should look for
1. modify the `biasconfig` variable to point to the path of the file that lists which files of the `biasDir` should be included in the biasing step of clustering

After modifying the script, run the following command from the top level directory of the repo:

`make cluster`

Now the results should be in the directory that was set up with the `outputDir`, and can be processed by the script at the path real\_analysis/mapped\_strands\_analysis\_starcode.py to generate erorrrate analysis and read distribution analyses. The list of options can be generated with:

python real\_analysis/mapped\_strands\_analysis\_starcode.py --help

The options that set up the analysis with the proper information are explained in more detail as follows:

--sample\_range: The range of experiments to include in one spread sheet. This is based on the assumption that all sequencing fastq files start with *sX* where *X* is an arbitrary ID number for the fastq file. This can be achieved witha simple renaming before performing all of the analysis. One should check the directory in which mapped strands have been dumped to see which range of sample ID's have been generated since one could generated disjoint ranges 1 at a time, e.g sampels 1-5 and 10-15 without 6-9.

--original\_encoding\_directory: path to the directory that represents the original encoded strands. Should be the same as the `biasDir` path previously used.

--stripped\_fastq\_directory: path to the stripped fastq data generated in the first series of steps, and should be the same as `outputDir` variable in the alignment.sh script.

--primer\_partition\_top\_directory: path to the top level directory of mapped strands. This should be the same as the `outputDir` variable in the cluster.sh script.

--output\_book: name of the excel spread sheet that data will be dumped to. In the book, there will be a separate sheet for each sample identified by --sample\_range.


